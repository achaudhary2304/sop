{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryan/.local/lib/python3.10/site-packages/torch/__config__.py:10: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._show_config()\n",
      "/home/aryan/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import to_undirected\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data \n",
    "df = pd.read_csv(r\"/home/aryan/sop_fd/neeww(1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using a subset of the data for prototyping\n",
    "sample_size = int(len(df)*.2)\n",
    "sampled_indices = random.sample(range(len(df)), sample_size)\n",
    "df = df.iloc[sampled_indices].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Graph and Add Nodes\n",
    "G = nx.Graph()\n",
    "num_users = len(df)\n",
    "G.add_nodes_from(range(num_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cosine Similarity Edge Formation\n",
    "feature_matrix = df.values\n",
    "for i in range(num_users):\n",
    "    for j in range(i + 1, num_users):\n",
    "        vec1 = feature_matrix[i, 0:8]  # Assuming columns 1-3 are features\n",
    "        vec2 = feature_matrix[j, 0:8]\n",
    "        similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "        if similarity >= 0.5:\n",
    "            G.add_edge(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# K-hop Graph Construction\n",
    "def khop_graph(G, k):\n",
    "    khop_G = nx.Graph()\n",
    "    for node in G.nodes:\n",
    "        neighbors = nx.single_source_shortest_path_length(G, node, cutoff=k)\n",
    "        for neighbor, dist in neighbors.items():\n",
    "            if dist <= k:\n",
    "                khop_G.add_edge(node, neighbor)\n",
    "    return khop_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-hop graph created with 500 nodes and 125250 edges.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "k = 3\n",
    "G_khop = khop_graph(G, k)\n",
    "print(f\"K-hop graph created with {len(G_khop.nodes)} nodes and {len(G_khop.edges)} edges.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3️⃣ Compute Normalized Laplacian ###\n",
    "A = nx.to_numpy_array(G_khop)\n",
    "D = np.diag(A.sum(axis=1))\n",
    "L = D - A  # Unnormalized Laplacian\n",
    "D_inv_sqrt = np.linalg.inv(np.sqrt(D))\n",
    "L_norm = np.eye(A.shape[0]) - np.matmul(D_inv_sqrt, A).dot(D_inv_sqrt)\n",
    "\n",
    "# Convert to PyTorch Tensor\n",
    "laplacian_tensor = torch.tensor(L_norm, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centrality calculation completed.\n"
     ]
    }
   ],
   "source": [
    "# Centrality Calculation on K-hop Graph\n",
    "centralities = {\n",
    "    'degree': nx.degree_centrality(G_khop),\n",
    "    'betweenness': nx.betweenness_centrality(G_khop),\n",
    "    'closeness': nx.closeness_centrality(G_khop),\n",
    "    'eigenvector': nx.eigenvector_centrality(G_khop, max_iter=1000)\n",
    "}\n",
    "\n",
    "print(\"Centrality calculation completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'a.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(centralities, file)  # 'wb' for write binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'a.pkl'\n",
    "with open(filename, 'rb') as file:\n",
    "    centralities = pickle.load(file)  # 'rb' for read binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature matrix with centralities (excluding user ID)\n",
    "X = np.array([[centralities['degree'][i],\n",
    "               centralities['betweenness'][i],\n",
    "               centralities['closeness'][i],\n",
    "               centralities['eigenvector'][i]]\n",
    "              for i in range(num_users)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIR Simulation on K-hop Graph\n",
    "def sir_simulation(G, patient_zero, beta=0.3, gamma=0.1, max_iter=50):\n",
    "    states = {n: 'S' for n in G.nodes()}\n",
    "    states[patient_zero] = 'I'\n",
    "    infected_count = [1]\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        new_infections, recoveries = 0, 0\n",
    "\n",
    "        for node in list(G.nodes()):\n",
    "            if states[node] == 'I':\n",
    "                for neighbor in G.neighbors(node):\n",
    "                    if states[neighbor] == 'S' and np.random.random() < beta:\n",
    "                        states[neighbor] = 'I'\n",
    "                        new_infections += 1\n",
    "\n",
    "                if np.random.random() < gamma:\n",
    "                    states[node] = 'R'\n",
    "                    recoveries += 1\n",
    "\n",
    "        infected_count.append(infected_count[-1] + new_infections - recoveries)\n",
    "\n",
    "        if infected_count[-1] == 0:\n",
    "            break\n",
    "\n",
    "    return max(infected_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIR simulation completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sir_labels = np.zeros(num_users)\n",
    "for i in range(num_users):\n",
    "    sir_labels[i] = sir_simulation(G_khop, i)\n",
    "print(\"SIR simulation completed.\")\n",
    "\n",
    "threshold = np.percentile(sir_labels, 80)\n",
    "y = (sir_labels >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'b.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(y, file)  # 'wb' for write binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'b.pkl'\n",
    "with open(filename, 'rb') as file:\n",
    "    y = pickle.load(file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_131599/1551633758.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'type'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array_equal(y, d))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert Graph to PyG Edge Index\n",
    "edge_index = torch.tensor(list(G_khop.edges())).t().contiguous()\n",
    "\n",
    "# Features and Labels\n",
    "features = torch.tensor(X, dtype=torch.float32)\n",
    "labels = torch.tensor(y, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCN Model with corrected initialization\n",
    "class TrustGCN(nn.Module):\n",
    "    def __init__(self, input_dim=4, hidden_dim=8):\n",
    "        super(TrustGCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, 16)\n",
    "        self.conv2 = GCNConv(16, 32)\n",
    "        self.conv3 = GCNConv(32, 64)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc3 = nn.Linear(16, 2)\n",
    "        \n",
    "    def forward(self, x, edge_index,laplacian):\n",
    "        x = torch.matmul(laplacian, x)\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.elu(self.conv2(x, edge_index))\n",
    "        x = F.elu(self.conv3(x, edge_index))\n",
    "        \n",
    "        # Fully connected processing\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "matmul(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_158702/1973684978.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_158702/923141595.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, laplacian)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlaplacian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlaplacian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlaplacian\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: matmul(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "edge_index = torch.tensor(list(G.edges())).t().contiguous()\n",
    "features = torch.tensor(X, dtype=torch.float32)\n",
    "labels = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# 5️⃣ Training with SIR-based Loss\n",
    "model = TrustGCN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output = model(features, laplacian_tensor)\n",
    "    loss = F.nll_loss(output, labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# 6️⃣ Trust Evaluation and Access Control\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    log_probs = model(features,laplacian_tensor)\n",
    "    influence_scores = torch.exp(log_probs[:, 1])\n",
    "\n",
    "trust_scores = influence_scores.numpy()\n",
    "\n",
    "num, bins = np.histogram(trust_scores, bins=10)\n",
    "bin_width = bins[1] - bins[0]\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "plt.bar(bin_centers, num, width=bin_width, align='center')\n",
    "plt.xlabel(\"Trust Scores\")\n",
    "plt.ylabel(\"Number of People\")\n",
    "plt.title(\"Distribution of Trust Scores\")\n",
    "plt.show()\n",
    "\n",
    "trust_threshold = 0.7\n",
    "connection_fading = 0.5\n",
    "\n",
    "def grant_access(user_id):\n",
    "    department = df.iloc[user_id][4:8].idxmax().split('_')[1]\n",
    "    trust = trust_scores[user_id]\n",
    "\n",
    "    if trust < trust_threshold:\n",
    "        return False, \"Insufficient trust score\"\n",
    "\n",
    "    if department == '3':\n",
    "        return True, \"Full access granted\"\n",
    "    else:\n",
    "        return True, \"Standard access granted\"\n",
    "\n",
    "for user_id in df.index:\n",
    "    access, message = grant_access(user_id)\n",
    "    print(f\"User {user_id}: {message}\")\n",
    "\n",
    "def apply_fading_factor(G, pl, di):\n",
    "    rho = (1 - pl + di) / 2\n",
    "    for u, v in G.edges():\n",
    "        G[u][v]['weight'] *= rho\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_158702/2482533478.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/shap/explainers/_permutation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[1;32m     98\u001b[0m     ):\n\u001b[1;32m     99\u001b[0m         \u001b[0;34m\"\"\"Explain the output of the model on the given arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         return super().__call__(\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/shap/explainers/_explainer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow_args\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" explainer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m             row_result = self.explain_row(\n\u001b[0m\u001b[1;32m    367\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0mrow_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/shap/explainers/_permutation.py\u001b[0m in \u001b[0;36mexplain_row\u001b[0;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *row_args)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;31m# evaluate the masked model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrow_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0mfull_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_masker_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0m_convert_delta_mask_to_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_masking_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/shap/utils/_masked_model.py\u001b[0m in \u001b[0;36m_full_masking_call\u001b[0;34m(self, masks, zero_index, batch_size)\u001b[0m\n\u001b[1;32m     89\u001b[0m                     \u001b[0mmasked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                     \u001b[0mmasked_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;31m# get a copy that won't get overwritten by the next iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "source": [
    "### 7️⃣ Apply SHAP for Explainability ###\n",
    "def model_predict(X):\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float)\n",
    "    return model(X_tensor, edge_index, laplacian_tensor).detach().numpy()\n",
    "\n",
    "explainer = shap.Explainer(model_predict, features)\n",
    "shap_values = explainer(features)\n",
    "shap.summary_plot(shap_values, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids_to_explain = list(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array = features.cpu().numpy()\n",
    "\n",
    "    # Create a Pandas DataFrame from the NumPy array\n",
    "dataframe = pd.DataFrame(numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add these imports at the top of your file\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_samples = 50 #Reduced to 50 for this example.\n",
    "selected_features = features[:num_samples]\n",
    "mask = (edge_index[0] < num_samples) & (edge_index[1] < num_samples)\n",
    "selected_edge_index = edge_index[:, mask]\n",
    "\n",
    "#Debugging code.\n",
    "print(f\"Max edge index value: {torch.max(selected_edge_index)}\")\n",
    "print(f\"Number of nodes: {selected_features.shape[0]}\")\n",
    "\n",
    "class TrustGCNWrapper(nn.Module):\n",
    "    def __init__(self, model, edge_index):\n",
    "        super(TrustGCNWrapper, self).__init__()\n",
    "        self.model = model\n",
    "        self.edge_index = edge_index\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x, self.edge_index)\n",
    "\n",
    "wrapped_model = TrustGCNWrapper(model, selected_edge_index)\n",
    "\n",
    "explainer = shap.GradientExplainer(wrapped_model, selected_features)\n",
    "shap_values = explainer.shap_values(selected_features)\n",
    "\n",
    "print(shap_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(centralities, shap_values[0], features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_with_shap(model, features, edge_index, user_ids_to_explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0040, 0.0000, 1.0000, 0.0447],\n",
      "        [1.0040, 0.0000, 1.0000, 0.0447],\n",
      "        [1.0040, 0.0000, 1.0000, 0.0447],\n",
      "        ...,\n",
      "        [1.0040, 0.0000, 1.0000, 0.0447],\n",
      "        [1.0040, 0.0000, 1.0000, 0.0447],\n",
      "        [1.0040, 0.0000, 1.0000, 0.0447]])\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# After your model training, add these explainability functions:\n",
    "print(features)\n",
    "def explain_with_shap(model, features, edge_index, user_ids_to_explain):\n",
    "    \"\"\"\n",
    "    Use SHAP to explain model decisions for specific users\n",
    "    \"\"\"\n",
    "    # Create a wrapper function that returns probabilities for both classes\n",
    "    def model_wrapper(x):\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.reshape(1, -1)\n",
    "        x_tensor = torch.tensor(x, dtype=torch.float32)\n",
    "        with torch.no_grad():\n",
    "            out = model(x_tensor, edge_index)\n",
    "        return torch.exp(out).numpy()  # Convert log-probs to probabilities\n",
    "    background = features.numpy()  # Use the actual feature matrix\n",
    "    # Initialize SHAP explainer with background samples\n",
    "      # Use 10 background samples\n",
    "    explainer = shap.KernelExplainer(\n",
    "        model_wrapper,\n",
    "        background,\n",
    "        link=\"logit\"\n",
    "    )\n",
    "    \n",
    "    explanations = {}\n",
    "    for user_id in user_ids_to_explain:\n",
    "        try:\n",
    "            # Get SHAP values for this user\n",
    "            user_features = features[user_id].numpy().reshape(1, -1)\n",
    "            shap_values = explainer.shap_values(\n",
    "                    user_features,\n",
    "                    nsamples=100\n",
    "                )\n",
    "            \n",
    "            # For binary classification, SHAP returns values for both classes\n",
    "            if isinstance(shap_values, list):\n",
    "                # Use values for the positive class (trusted)\n",
    "                shap_values = shap_values[1]\n",
    "            \n",
    "            # Store explanation\n",
    "            explanations[user_id] = {\n",
    "                'features': ['degree', 'betweenness', 'closeness', 'eigenvector'],\n",
    "                'shap_values': shap_values[0],  # Get first (and only) sample\n",
    "                'base_value': explainer.expected_value[1],\n",
    "                'trust_score': trust_scores[user_id],\n",
    "                'access_granted': trust_scores[user_id] >= trust_threshold\n",
    "            }\n",
    "            \n",
    "            # Plot the explanation\n",
    "            shap.force_plot(\n",
    "                explainer.expected_value[1],\n",
    "                shap_values[0],\n",
    "                user_features[0],  # Use the flattened features\n",
    "                feature_names=['degree', 'betweenness', 'closeness', 'eigenvector'],\n",
    "                matplotlib=True,\n",
    "                show=False\n",
    "            )\n",
    "            plt.title(f\"SHAP explanation for User {user_id}\")\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to explain user {user_id}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 500 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "Widget Javascript not detected.  It may not be installed or enabled properly. Reconnecting the current kernel may help.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457de564014642368c19519aa2adc75a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x783877d57910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aryan/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/home/aryan/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "  File \"/home/aryan/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 150, in display\n",
      "    d = self.format_dict\n",
      "  File \"/home/aryan/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1462, in format_dict\n",
      "    'colour': self.colour}\n",
      "  File \"/home/aryan/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 195, in colour\n",
      "    return self.container.children[-2].style.bar_color\n",
      "AttributeError: 'FloatProgress' object has no attribute 'style'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to explain user 0: 'FloatProgress' object has no attribute 'style'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly. Reconnecting the current kernel may help.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b0a8d857fc43218fcee1eeafcbfad1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to explain user 1: 'FloatProgress' object has no attribute 'style'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly. Reconnecting the current kernel may help.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffecc26e8d0d439aa9c5f31b7cefabdd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to explain user 2: 'FloatProgress' object has no attribute 'style'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly. Reconnecting the current kernel may help.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406f1b07e9a246ddb6778fed55fdc902"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x783877d57910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aryan/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/home/aryan/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "  File \"/home/aryan/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 150, in display\n",
      "    d = self.format_dict\n",
      "  File \"/home/aryan/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1462, in format_dict\n",
      "    'colour': self.colour}\n",
      "  File \"/home/aryan/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 195, in colour\n",
      "    return self.container.children[-2].style.bar_color\n",
      "AttributeError: 'FloatProgress' object has no attribute 'style'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x783877d57910>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aryan/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/home/aryan/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "  File \"/home/aryan/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 150, in display\n",
      "    d = self.format_dict\n",
      "  File \"/home/aryan/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1462, in format_dict\n",
      "    'colour': self.colour}\n",
      "  File \"/home/aryan/.local/lib/python3.10/site-packages/tqdm/notebook.py\", line 195, in colour\n",
      "    return self.container.children[-2].style.bar_color\n",
      "AttributeError: 'FloatProgress' object has no attribute 'style'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to explain user 3: 'FloatProgress' object has no attribute 'style'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly. Reconnecting the current kernel may help.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c575be683a7a4c3489cc4f923717e4e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to explain user 4: 'FloatProgress' object has no attribute 'style'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explain_with_shap(model, features, edge_index, user_ids_to_explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
